\subsection{Organization}\label{sec:compiler:vm}

At the lowest level, Factor is written atop a C++ \gls{VM} that is responsible
for basic runtime services.  This is where the non-optimizing base compiler is
implemented.  It's the base compiler's job to compile the simplest primitives:
operations that push literals onto the data stack, \factor|call|, \factor|if|,
\factor|dip|, words that access tuple slots as laid out in memory, stack
shufflers, math operators, functions to allocate/deallocate call stack frames,
etc.  The aim of the base compiler is to generate native machine code as fast
as possible.  To this end, these primitives correspond to their own stubs of
assembly code.  Different stubs are generated by Factor depending on the
instruction set supported by the particular machine in use.  Thus, the base
compiler need only make a single pass over the source code, emitting these
machine instructions as it goes.

The \gls{VM} also handles method dispatch and memory management.  Method
dispatch incorporates a \term{polymorphic inline cache} to speed up generic
words.  Each generic word's call site is associated with a state:
\begin{itemize}
  \item In the \term{cold} state, the call site's instruction computes the
        right method for the class being dispatched upon, which is the
        operation we're trying to avoid.  As it does this, a polymorphic inline
        cache stub is generated, thus transitioning it to the next state.
  \item In the \term{inline cache} state, a stub has been generated that caches
        the locations of methods for classes that have already been seen.  This
        way, if a generic word at a particular call site is invoked often upon
        only a small number of classes, we don't need to waste as much time
        doing method lookup.  By default, if more than $3$ different classes
        are dispatched upon, we transition to the next state.
  \item In the \term{megamorphic} state, the call instruction points to a
        larger cache that is allocated for the specific generic word (i.e., it
        is shared by all call sites).  While not as efficient as an inline
        cache, this can still improve the performance of method dispatch.
\end{itemize}

To manage memory, the Factor \gls{VM} uses a generational \gls{GC}, which
carves out sections of space on the heap for objects of different ages.
Garbage in the oldest generation is collected with a mark-sweep-compact
algorithm, while younger generations rely on a copying collector\todo{cite?}.
This way, the \gls{GC} is specialized for large numbers of short-lived objects
that will stay in the younger generations without being promoted to the older
generation.  In the oldest space, even compiled code can be compacted.  This is
to avoid heap fragmentation in applications that must call the compiler at
runtime, such as Factor's interactive development environment.

%dls.pdf verbatim:

The Factor implementation is structured into a virtual ma- chine (VM) written
in C++ and a core library written in Factor. The VM provides essential runtime
services, such as garbage collection, method dispatch, and a base compiler.
The rest is implemented in Factor.

The VM loads an image ﬁle containing a memory snap- shot, as in many Smalltalk
and Lisp systems. The source parser manipulates the code in the image as new
deﬁnitions are read in from source ﬁles. The source parser is written in Factor
and can be extended from user code (Section 2.3.1).  The image can be saved,
and effectively acts as a cache for compiled code.  Values are referenced using
tagged pointers [29]. Small integers are stored directly inside a pointer’s
payload. Large integers and ﬂoating point numbers are boxed in the heap;
however, compiler optimizations can in many cases elimi- nate this boxing and
store ﬂoating point temporaries in regis- ters. Specialized data structures are
also provided for storing packed binary data without boxing (Section 2.4).

The optimizing compiler is writ- ten in Factor and is
used to compile most code.  Factor is partially self-hosting and there is a
bootstrap process, similar to Steel Bank Common Lisp [38]. An im- age
generation tool is run from an existing Factor instance to produce a new
bootstrap image containing the parser, ob- ject system, and core libraries. The
Factor VM is then run with the bootstrap image, which loads a minimal set of
li- braries which get compiled with the base compiler. The op- timizing
compiler is then loaded, and the base libraries are recompiled with the
optimizing compiler. With the optimiz- ing compiler now available, additional
libraries and tools are loaded and compiled, including Factor’s GUI develop-
ment environment. Once this process completes, the image is saved, resulting in
a full development image.
