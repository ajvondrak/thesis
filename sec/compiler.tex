\inputlst{tree}

\begin{itemize}
\item
\begin{flushleft}
Loading constants:
\Verb|##load-integer|,
\Verb|##load-reference|
\end{flushleft}

\item
\begin{flushleft}
Optimized loading of constants, inserted by representation selection:
\Verb|##load-tagged|,
\Verb|##load-float|,
\Verb|##load-double|,
\Verb|##load-vector|
\end{flushleft}

\item
\begin{flushleft}
Stack operations:
\Verb|##peek|,
\Verb|##replace|,
\Verb|##replace-imm|,
\Verb|##inc-d|,
\Verb|##inc-r|
\end{flushleft}

\item
\begin{flushleft}
Subroutine calls:
\Verb|##call|,
\Verb|##jump|,
\Verb|##prologue|,
\Verb|##epilogue|,
\Verb|##return|
\end{flushleft}

\item
\begin{flushleft}
Inhibiting \gls{TCO}:
\Verb|##no-tco|
\end{flushleft}

\item
\begin{flushleft}
Jump tables:
\Verb|##dispatch|
\end{flushleft}

\item
\begin{flushleft}
Slot access:
\Verb|##slot|,
\Verb|##slot-imm|,
\Verb|##set-slot|,
\Verb|##set-slot-imm|
\end{flushleft}

\item
\begin{flushleft}
Register transfers:
\Verb|##copy|,
\Verb|##tagged>integer|
\end{flushleft}

\item
\begin{flushleft}
Integer arithmetic:
\Verb|##add|,
\Verb|##add-imm|,
\Verb|##sub|,
\Verb|##sub-imm|,
\Verb|##mul|,
\Verb|##mul-imm|,
\Verb|##and|,
\Verb|##and-imm|,
\Verb|##or|,
\Verb|##or-imm|,
\Verb|##xor|,
\Verb|##xor-imm|,
\Verb|##shl|,
\Verb|##shl-imm|,
\Verb|##shr|,
\Verb|##shr-imm|,
\Verb|##sar|,
\Verb|##sar-imm|,
\Verb|##min|,
\Verb|##max|,
\Verb|##not|,
\Verb|##neg|,
\Verb|##log2|,
\Verb|##bit-count|
\end{flushleft}

\item
\begin{flushleft}
Float arithmetic:
\Verb|##add-float|,
\Verb|##sub-float|,
\Verb|##mul-float|,
\Verb|##div-float|,
\Verb|##min-float|,
\Verb|##max-float|,
\Verb|##sqrt|
\end{flushleft}

\item
\begin{flushleft}
Single/double float conversion:
\Verb|##single>double-float|,
\Verb|##double>single-float|
\end{flushleft}

\item
\begin{flushleft}
Float/integer conversion:
\Verb|##float>integer|,
\Verb|##integer>float|
\end{flushleft}

\item
\begin{flushleft}
SIMD operations:
\Verb|##zero-vector|,
\Verb|##fill-vector|,
\Verb|##gather-vector-2|,
\Verb|##gather-int-vector-2|,
\Verb|##gather-vector-4|,
\Verb|##gather-int-vector-4|,
\Verb|##select-vector|,
\Verb|##shuffle-vector|,
\Verb|##shuffle-vector-halves-imm|,
\Verb|##shuffle-vector-imm|,
\Verb|##tail>head-vector|,
\Verb|##merge-vector-head|,
\Verb|##merge-vector-tail|,
\Verb|##float-pack-vector|,
\Verb|##signed-pack-vector|,
\Verb|##unsigned-pack-vector|,
\Verb|##unpack-vector-head|,
\Verb|##unpack-vector-tail|,
\Verb|##integer>float-vector|,
\Verb|##float>integer-vector|,
\Verb|##compare-vector|,
\Verb|##test-vector|,
\Verb|##test-vector-branch|,
\Verb|##add-vector|,
\Verb|##saturated-add-vector|,
\Verb|##add-sub-vector|,
\Verb|##sub-vector|,
\Verb|##saturated-sub-vector|,
\Verb|##mul-vector|,
\Verb|##mul-high-vector|,
\Verb|##mul-horizontal-add-vector|,
\Verb|##saturated-mul-vector|,
\Verb|##div-vector|,
\Verb|##min-vector|,
\Verb|##max-vector|,
\Verb|##avg-vector|,
\Verb|##dot-vector|,
\Verb|##sad-vector|,
\Verb|##horizontal-add-vector|,
\Verb|##horizontal-sub-vector|,
\Verb|##horizontal-shl-vector-imm|,
\Verb|##horizontal-shr-vector-imm|,
\Verb|##abs-vector|,
\Verb|##sqrt-vector|,
\Verb|##and-vector|,
\Verb|##andn-vector|,
\Verb|##or-vector|,
\Verb|##xor-vector|,
\Verb|##not-vector|,
\Verb|##shl-vector-imm|,
\Verb|##shr-vector-imm|,
\Verb|##shl-vector|,
\Verb|##shr-vector|
\end{flushleft}

\item
\begin{flushleft}
Scalar/vector conversion:
\Verb|##scalar>integer|,
\Verb|##integer>scalar|,
\Verb|##vector>scalar|,
\Verb|##scalar>vector|
\end{flushleft}

\item
\begin{flushleft}
Boxing and unboxing aliens:
\Verb|##box-alien|,
\Verb|##box-displaced-alien|,
\Verb|##unbox-any-c-ptr|,
\Verb|##unbox-alien|
\end{flushleft}

\item
\begin{flushleft}
Zero-extending and sign-extending integers:
\Verb|##convert-integer|
\end{flushleft}

\item
\begin{flushleft}
Raw memory access:
\Verb|##load-memory|,
\Verb|##load-memory-imm|,
\Verb|##store-memory|,
\Verb|##store-memory-imm|
\end{flushleft}

\item
\begin{flushleft}
Memory allocation:
\Verb|##allot|,
\Verb|##write-barrier|,
\Verb|##write-barrier-imm|,
\Verb|##alien-global|,
\Verb|##vm-field|,
\Verb|##set-vm-field|
\end{flushleft}

\item
\begin{flushleft}
The \gls{FFI}:
\Verb|##unbox|,
\Verb|##unbox-long-long|,
\Verb|##local-allot|,
\Verb|##box|,
\Verb|##box-long-long|,
\Verb|##alien-invoke|,
\Verb|##alien-indirect|,
\Verb|##alien-assembly|,
\Verb|##callback-inputs|,
\Verb|##callback-outputs|
\end{flushleft}

\item
\begin{flushleft}
Control flow:
\Verb|##phi|,
\Verb|##branch|
\end{flushleft}

\item
\begin{flushleft}
Tagged conditionals:
\Verb|##compare-branch|,
\Verb|##compare-imm-branch|,
\Verb|##compare|,
\Verb|##compare-imm|
\end{flushleft}

\item
\begin{flushleft}
Integer conditionals:
\Verb|##compare-integer-branch|,
\Verb|##compare-integer-imm-branch|,
\Verb|##test-branch|,
\Verb|##test-imm-branch|,
\Verb|##compare-integer|,
\Verb|##compare-integer-imm|,
\Verb|##test|,
\Verb|##test-imm|
\end{flushleft}

\item
\begin{flushleft}
Float conditionals:
\Verb|##compare-float-ordered-branch|,
\Verb|##compare-float-unordered-branch|,
\Verb|##compare-float-ordered|,
\Verb|##compare-float-unordered|
\end{flushleft}

\item
\begin{flushleft}
Overflowing arithmetic:
\Verb|##fixnum-add|,
\Verb|##fixnum-sub|,
\Verb|##fixnum-mul|,
\Verb|##save-context|
\end{flushleft}

\item
\begin{flushleft}
\Gls{GC} checks:
\Verb|##check-nursery-branch|,
\Verb|##call-gc|
\end{flushleft}

\item
\begin{flushleft}
Spills and reloads, inserted by the register allocator:
\Verb|##spill|,
\Verb|##reload|
\end{flushleft}
\end{itemize}

% dls.pdf verbatim:

The optimizing compiler is structured as a series of passes operating on two
intermediate representations (IRs), referred to as high-level IR and low-level
IR. High-level IR represents control ﬂow in a similar manner to a
block-structured pro- gramming language. Low-level IR represents control ﬂow
with a control ﬂow graph of basic blocks. Both intermediate forms make use of
single static assignment (SSA) form to improve the accuracy and efﬁciency of
analysis [12].

High-level IR is constructed by the stack effect checker.  Macro expansion and
quotation inlining is performed by the stack checker online while high-level IR
is being con- structed. The front end does not deal with local variables, as
these have already been eliminated.

When static type information is available, Factor’s compiler can eliminate
runtime method dispatch and allocation of in- termediate objects, generating
code specialized to the under- lying data structures. This resembles previous
work in soft typing [10]. Factor provides several mechanisms to facilitate
static type propagation:

\begin{itemize}

\item Functions can be annotated as inline, causing the compiler to replace
calls to the function with the function body.

\item Functions can be hinted, causing the compiler to gener- ate multiple
specialized versions of the function, each assuming different input types, with
dispatch at the en- try point to choose the best-ﬁtting specialization for the
given inputs.  

\item Methods on generic functions propagate the type infor- mation for their
dispatched-on inputs.  

\item Functions can be declared with static input and output types using the
typed library.

\end{itemize}

The three major optimizations performed on high-level IR are sparse conditional
constant propagation (SCCP [45]), escape analysis with scalar replacement, and
overﬂow check elimination using modular arithmetic properties.  The major
features of our SCCP implementation are an extended value lattice, rewrite
rules, and ﬂow sensitivity.  Our SCCP implementation augments the standard
single- level constant lattice with information about object types, numeric
intervals, array lengths and tuple slot types. Type transfer functions are
permitted to replace nodes in the IR with inline expansions. Type functions are
deﬁned on many of the core language words.  SCCP is used to statically dispatch
generic word calls by inlining a speciﬁc method body at the call site. This
inlining generates new type information and new opportunities for constant
folding, simpliﬁcation and further inlining. In par- ticular, generic
arithmetic operations which require dynamic dispatch in the general case can be
lowered to simpler opera- tions as type information is discovered. Overﬂow
checks can be removed from integer operations using numeric interval
information. The analysis can represent ﬂow-sensitive type information.
Additionally, calls to closures which combina- tor inlining cannot eliminate
are eliminated when enough in- formation is available [16].  An escape analysis
pass is used to discover object alloca- tions which are not stored on the heap
or returned from the current function. Scalar replacement is performed on such
allocations, converting tuple slots into SSA values.  The modular arithmetic
optimization pass identiﬁes in- teger expressions in which the ﬁnal result is
taken to be modulo a power of two and removes unnecessary overﬂow checks from
any intermediate addition and multiplication operations. This novel
optimization is global and can operate over loops.

Low-level IR is built from high-level IR by analyzing control ﬂow and making
stack reads and writes explicit. During this construction phase and a
subsequent branch splitting phase, the SSA structure of high-level IR is lost.
SSA form is recon- structed using the SSA construction algorithm described in
[8], with the minor variation that we construct pruned SSA form rather than
semi-pruned SSA, by ﬁrst computing live- ness. To avoid computing iterated
dominance frontiers, we use the TDMSC algorithm from [13].  The main
optimizations performed on low-level IR are local dead store and redundant load
elimination, local value numbering, global copy propagation, representation
selec- tion, and instruction scheduling.  The local value numbering pass
eliminates common sub- expressions and folds expressions with constant operands
[9]. Following value numbering and copy propagation, a representation selection
pass decides when to unbox ﬂoating point and SIMD values. A form of instruction
scheduling intended to reduce register pressure is performed on low- level IR
as the last step before leaving SSA form [39].  We use the second-chance
binpacking variation of the lin- ear scan register allocation algorithm [43,
47]. Our variant does not take φ nodes into account, so SSA form is destruc-
ted ﬁrst by eliminating φ nodes while simultaneously per- forming copy
coalescing, using the method described in [6].
