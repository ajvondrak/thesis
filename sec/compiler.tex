\section{The Factor Compiler}\label{sec:compiler}

If we could sort programming languages by the fuzzy notions we tend to have
about how ``high-level'' they are, toward the high end we'd find
dynamically-typed languages like Python, Ruby, and PHP---all of which are
generally more interpreted than compiled\todo{Though there are projects for
this}.  Despite being as high-level as these popular languages, Factor's
implementation is driven by performance.  Factor source is always compiled to
native machine code using either its simple, non-optimizing compiler or (more
typically) the optimizing compiler that performs several sorts of data and
control flow analyses.  In this \lcnamecref{sec:compiler}, we look at the
general architecture of Factor's implementation, after which we place a
particular emphasis on the transformations performed by the optimizing
compiler.

%\input{sec/compiler/vm}
\input{sec/compiler/tree}
%\input{sec/compiler/cfg}

% dls.pdf verbatim:

%Low-level IR is built from high-level IR by analyzing control ﬂow and making
%stack reads and writes explicit. During this construction phase and a
%subsequent branch splitting phase, the SSA structure of high-level IR is lost.
%SSA form is recon- structed using the SSA construction algorithm described in
%[8], with the minor variation that we construct pruned SSA form rather than
%semi-pruned SSA, by ﬁrst computing live- ness. To avoid computing iterated
%dominance frontiers, we use the TDMSC algorithm from [13].  The main
%optimizations performed on low-level IR are local dead store and redundant load
%elimination, local value numbering, global copy propagation, representation
%selec- tion, and instruction scheduling.  The local value numbering pass
%eliminates common sub- expressions and folds expressions with constant operands
%[9]. Following value numbering and copy propagation, a representation selection
%pass decides when to unbox ﬂoating point and SIMD values. A form of instruction
%scheduling intended to reduce register pressure is performed on low- level IR
%as the last step before leaving SSA form [39].  We use the second-chance
%binpacking variation of the lin- ear scan register allocation algorithm [43,
%47]. Our variant does not take φ nodes into account, so SSA form is destruc-
%ted ﬁrst by eliminating φ nodes while simultaneously per- forming copy
%coalescing, using the method described in [6].
